{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/user/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/user/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/user/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os, json, gzip \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>cuisine_style</th>\n",
       "      <th>ranking</th>\n",
       "      <th>rating</th>\n",
       "      <th>price_range</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews</th>\n",
       "      <th>restaurant_url</th>\n",
       "      <th>restaurant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>Zurich</td>\n",
       "      <td>['American']</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>$</td>\n",
       "      <td>11</td>\n",
       "      <td>['Hangover', 'Most expensive McDonalds in the ...</td>\n",
       "      <td>https://www.tripadvisor.com/Restaurant_Review-...</td>\n",
       "      <td>d8796498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Yumi Hana</td>\n",
       "      <td>Zurich</td>\n",
       "      <td>['Korean', 'Japanese']</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>50</td>\n",
       "      <td>['What once was a 5 points Restaurant is clo.....</td>\n",
       "      <td>https://www.tripadvisor.com/Restaurant_Review-...</td>\n",
       "      <td>d2070374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Peking Garden</td>\n",
       "      <td>Zurich</td>\n",
       "      <td>['Chinese', 'Asian']</td>\n",
       "      <td>1544.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>$</td>\n",
       "      <td>41</td>\n",
       "      <td>['Just if no other choice!', 'Ok Chinese food']</td>\n",
       "      <td>https://www.tripadvisor.com/Restaurant_Review-...</td>\n",
       "      <td>d2005395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Long Huang</td>\n",
       "      <td>Zurich</td>\n",
       "      <td>['Chinese', 'Vietnamese']</td>\n",
       "      <td>1545.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>14</td>\n",
       "      <td>['Good', 'As the name implies, long wait and b...</td>\n",
       "      <td>https://www.tripadvisor.com/Restaurant_Review-...</td>\n",
       "      <td>d11963037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Restaurant Hallo</td>\n",
       "      <td>Zurich</td>\n",
       "      <td>['European', 'Cafe']</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>21</td>\n",
       "      <td>['Really just ok', 'BRASILEIROS NÃO SÃO BEM-VI...</td>\n",
       "      <td>https://www.tripadvisor.com/Restaurant_Review-...</td>\n",
       "      <td>d7195130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              name    city              cuisine_style  ranking  \\\n",
       "0           0        McDonald's  Zurich               ['American']   1540.0   \n",
       "1           2         Yumi Hana  Zurich     ['Korean', 'Japanese']   1542.0   \n",
       "2           3     Peking Garden  Zurich       ['Chinese', 'Asian']   1544.0   \n",
       "3           4        Long Huang  Zurich  ['Chinese', 'Vietnamese']   1545.0   \n",
       "4           5  Restaurant Hallo  Zurich       ['European', 'Cafe']   1547.0   \n",
       "\n",
       "   rating price_range  number_of_reviews  \\\n",
       "0     2.5           $                 11   \n",
       "1     3.0    $$ - $$$                 50   \n",
       "2     2.5           $                 41   \n",
       "3     2.5    $$ - $$$                 14   \n",
       "4     3.0    $$ - $$$                 21   \n",
       "\n",
       "                                             reviews  \\\n",
       "0  ['Hangover', 'Most expensive McDonalds in the ...   \n",
       "1  ['What once was a 5 points Restaurant is clo.....   \n",
       "2    ['Just if no other choice!', 'Ok Chinese food']   \n",
       "3  ['Good', 'As the name implies, long wait and b...   \n",
       "4  ['Really just ok', 'BRASILEIROS NÃO SÃO BEM-VI...   \n",
       "\n",
       "                                      restaurant_url restaurant_id  \n",
       "0  https://www.tripadvisor.com/Restaurant_Review-...      d8796498  \n",
       "1  https://www.tripadvisor.com/Restaurant_Review-...      d2070374  \n",
       "2  https://www.tripadvisor.com/Restaurant_Review-...      d2005395  \n",
       "3  https://www.tripadvisor.com/Restaurant_Review-...     d11963037  \n",
       "4  https://www.tripadvisor.com/Restaurant_Review-...      d7195130  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/final_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews</th>\n",
       "      <th>restaurant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>['Hangover', 'Most expensive McDonalds in the ...</td>\n",
       "      <td>d8796498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>['What once was a 5 points Restaurant is clo.....</td>\n",
       "      <td>d2070374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.5</td>\n",
       "      <td>['Just if no other choice!', 'Ok Chinese food']</td>\n",
       "      <td>d2005395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.5</td>\n",
       "      <td>['Good', 'As the name implies, long wait and b...</td>\n",
       "      <td>d11963037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>['Really just ok', 'BRASILEIROS NÃO SÃO BEM-VI...</td>\n",
       "      <td>d7195130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71590</th>\n",
       "      <td>2.5</td>\n",
       "      <td>['Good food and nice experience', 'Disappointi...</td>\n",
       "      <td>d697907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71591</th>\n",
       "      <td>3.5</td>\n",
       "      <td>['Good service', 'nice atmoshphere']</td>\n",
       "      <td>d1187556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71592</th>\n",
       "      <td>2.0</td>\n",
       "      <td>['Worst New Year’s Eve experience', 'HORRIBLE']</td>\n",
       "      <td>d939089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71593</th>\n",
       "      <td>3.0</td>\n",
       "      <td>['Horrible!', 'It was really horrible, I would...</td>\n",
       "      <td>d1551957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71594</th>\n",
       "      <td>4.5</td>\n",
       "      <td>['Super local eatery', 'Small and charming pla...</td>\n",
       "      <td>d5768767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71595 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating                                            reviews restaurant_id\n",
       "0         2.5  ['Hangover', 'Most expensive McDonalds in the ...      d8796498\n",
       "1         3.0  ['What once was a 5 points Restaurant is clo.....      d2070374\n",
       "2         2.5    ['Just if no other choice!', 'Ok Chinese food']      d2005395\n",
       "3         2.5  ['Good', 'As the name implies, long wait and b...     d11963037\n",
       "4         3.0  ['Really just ok', 'BRASILEIROS NÃO SÃO BEM-VI...      d7195130\n",
       "...       ...                                                ...           ...\n",
       "71590     2.5  ['Good food and nice experience', 'Disappointi...       d697907\n",
       "71591     3.5               ['Good service', 'nice atmoshphere']      d1187556\n",
       "71592     2.0    ['Worst New Year’s Eve experience', 'HORRIBLE']       d939089\n",
       "71593     3.0  ['Horrible!', 'It was really horrible, I would...      d1551957\n",
       "71594     4.5  ['Super local eatery', 'Small and charming pla...      d5768767\n",
       "\n",
       "[71595 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Unnamed: 0','name', 'city', 'cuisine_style', 'ranking', 'price_range', 'number_of_reviews', 'restaurant_url'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental preprocessing tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "def ReviewProcessing(df):\n",
    "  # remove non alphanumeric \n",
    "  df['review_cleaned'] = df.reviews.str.replace('[^a-zA-Z0-9 ]', '')\n",
    "  # lowercase\n",
    "  df.review_cleaned = df.review_cleaned.str.lower()\n",
    "  # split into list\n",
    "  df.review_cleaned = df.review_cleaned.str.split(' ')\n",
    "  # remove stopwords\n",
    "  df.review_cleaned = df.review_cleaned.apply(lambda x: [item for item in x if item not in stopwords_list])\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "  tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "  tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "  return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def get_lemmatize(sent):\n",
    "  return \" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sent)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nh/n1r42zln7wb03k411lj0rwdc0000gn/T/ipykernel_1440/1177820914.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['review_cleaned'] = df.reviews.str.replace('[^a-zA-Z0-9 ]', '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>cuisine_style</th>\n",
       "      <th>ranking</th>\n",
       "      <th>rating</th>\n",
       "      <th>price_range</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews</th>\n",
       "      <th>restaurant_url</th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>review_cleaned</th>\n",
       "      <th>review_cleaned_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>Zurich</td>\n",
       "      <td>['American']</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>$</td>\n",
       "      <td>11</td>\n",
       "      <td>['Hangover', 'Most expensive McDonalds in the ...</td>\n",
       "      <td>https://www.tripadvisor.com/Restaurant_Review-...</td>\n",
       "      <td>d8796498</td>\n",
       "      <td>hangover expensive mcdonalds world</td>\n",
       "      <td>hangover expensive mcdonalds world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Yumi Hana</td>\n",
       "      <td>Zurich</td>\n",
       "      <td>['Korean', 'Japanese']</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>50</td>\n",
       "      <td>['What once was a 5 points Restaurant is clo.....</td>\n",
       "      <td>https://www.tripadvisor.com/Restaurant_Review-...</td>\n",
       "      <td>d2070374</td>\n",
       "      <td>5 points restaurant clo beware owner</td>\n",
       "      <td>5 point restaurant clo beware owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Peking Garden</td>\n",
       "      <td>Zurich</td>\n",
       "      <td>['Chinese', 'Asian']</td>\n",
       "      <td>1544.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>$</td>\n",
       "      <td>41</td>\n",
       "      <td>['Just if no other choice!', 'Ok Chinese food']</td>\n",
       "      <td>https://www.tripadvisor.com/Restaurant_Review-...</td>\n",
       "      <td>d2005395</td>\n",
       "      <td>choice ok chinese food</td>\n",
       "      <td>choice ok chinese food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Long Huang</td>\n",
       "      <td>Zurich</td>\n",
       "      <td>['Chinese', 'Vietnamese']</td>\n",
       "      <td>1545.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>14</td>\n",
       "      <td>['Good', 'As the name implies, long wait and b...</td>\n",
       "      <td>https://www.tripadvisor.com/Restaurant_Review-...</td>\n",
       "      <td>d11963037</td>\n",
       "      <td>good name implies long wait bad ser</td>\n",
       "      <td>good name implies long wait bad ser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Restaurant Hallo</td>\n",
       "      <td>Zurich</td>\n",
       "      <td>['European', 'Cafe']</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>21</td>\n",
       "      <td>['Really just ok', 'BRASILEIROS NÃO SÃO BEM-VI...</td>\n",
       "      <td>https://www.tripadvisor.com/Restaurant_Review-...</td>\n",
       "      <td>d7195130</td>\n",
       "      <td>really ok brasileiros bemvindos</td>\n",
       "      <td>really ok brasileiros bemvindos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              name    city              cuisine_style  ranking  \\\n",
       "0           0        McDonald's  Zurich               ['American']   1540.0   \n",
       "1           2         Yumi Hana  Zurich     ['Korean', 'Japanese']   1542.0   \n",
       "2           3     Peking Garden  Zurich       ['Chinese', 'Asian']   1544.0   \n",
       "3           4        Long Huang  Zurich  ['Chinese', 'Vietnamese']   1545.0   \n",
       "4           5  Restaurant Hallo  Zurich       ['European', 'Cafe']   1547.0   \n",
       "\n",
       "   rating price_range  number_of_reviews  \\\n",
       "0     2.5           $                 11   \n",
       "1     3.0    $$ - $$$                 50   \n",
       "2     2.5           $                 41   \n",
       "3     2.5    $$ - $$$                 14   \n",
       "4     3.0    $$ - $$$                 21   \n",
       "\n",
       "                                             reviews  \\\n",
       "0  ['Hangover', 'Most expensive McDonalds in the ...   \n",
       "1  ['What once was a 5 points Restaurant is clo.....   \n",
       "2    ['Just if no other choice!', 'Ok Chinese food']   \n",
       "3  ['Good', 'As the name implies, long wait and b...   \n",
       "4  ['Really just ok', 'BRASILEIROS NÃO SÃO BEM-VI...   \n",
       "\n",
       "                                      restaurant_url restaurant_id  \\\n",
       "0  https://www.tripadvisor.com/Restaurant_Review-...      d8796498   \n",
       "1  https://www.tripadvisor.com/Restaurant_Review-...      d2070374   \n",
       "2  https://www.tripadvisor.com/Restaurant_Review-...      d2005395   \n",
       "3  https://www.tripadvisor.com/Restaurant_Review-...     d11963037   \n",
       "4  https://www.tripadvisor.com/Restaurant_Review-...      d7195130   \n",
       "\n",
       "                         review_cleaned            review_cleaned_lemmatized  \n",
       "0    hangover expensive mcdonalds world   hangover expensive mcdonalds world  \n",
       "1  5 points restaurant clo beware owner  5 point restaurant clo beware owner  \n",
       "2                choice ok chinese food               choice ok chinese food  \n",
       "3   good name implies long wait bad ser  good name implies long wait bad ser  \n",
       "4       really ok brasileiros bemvindos      really ok brasileiros bemvindos  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = ReviewProcessing(df)\n",
    "clean_data.review_cleaned = clean_data.review_cleaned.apply(' '.join)\n",
    "clean_data['review_cleaned_lemmatized'] = clean_data.review_cleaned.apply(get_lemmatize)\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = clean_data['review_cleaned_lemmatized']\n",
    "y = clean_data['rating']\n",
    "y=y.astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = Pipeline([('vectorize', CountVectorizer(ngram_range=(1, 2))),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier()),\n",
    "               ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(max_iter=500)),\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([4. , 4.5, 4. , ..., 4.5, 4. , 5. ]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nh/n1r42zln7wb03k411lj0rwdc0000gn/T/ipykernel_1440/1118386123.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Naive Bayes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred_nb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Naive Bayes:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_nb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0mlabelbin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelbin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelbin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mof\u001b[0m \u001b[0mCSR\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \"\"\"\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: (array([4. , 4.5, 4. , ..., 4.5, 4. , 5. ]),)"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "print(\"Naive Bayes:\\n\")\n",
    "print(accuracy_score(y_test, y_pred_nb))\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "# SGD Classifier\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred_sgd = sgd.predict(X_test)\n",
    "print(\"SGD Classifier:\\n\")\n",
    "print(accuracy_score(y_test, y_pred_sgd))\n",
    "print(confusion_matrix(y_test, y_pred_sgd))\n",
    "print(classification_report(y_test, y_pred_sgd))\n",
    "\n",
    "# Logistic Regression\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_log = logreg.predict(X_test)\n",
    "print(\"Logistic regression:\\n\")\n",
    "print(accuracy_score(y_test, y_pred_log))\n",
    "print(confusion_matrix(y_test, y_pred_log))\n",
    "print(classification_report(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Pipeline(steps=[('vect', CountVectorizer(ngram_range=(1, 2))),\n",
      "                ('tfidf', TfidfTransformer()),\n",
      "                ('clf', LogisticRegression(C=1, max_iter=500, solver='saga'))])\n",
      "0.7097039209781292\n",
      "[[   0    2   16   11    0]\n",
      " [   0    2  151  140    0]\n",
      " [   0    6  862 2558    2]\n",
      " [   0    5  545 9284    4]\n",
      " [   0    0    5  721    5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        29\n",
      "           2       0.13      0.01      0.01       293\n",
      "           3       0.55      0.25      0.34      3428\n",
      "           4       0.73      0.94      0.82      9838\n",
      "           5       0.45      0.01      0.01       731\n",
      "\n",
      "    accuracy                           0.71     14319\n",
      "   macro avg       0.37      0.24      0.24     14319\n",
      "weighted avg       0.66      0.71      0.65     14319\n",
      "\n",
      "0.7090578951044068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid=[{'clf__solver': ['lbfgs', 'sag', 'saga'],\n",
    "       'clf__C': [0.01, 0.1, 1]}]\n",
    "lr = GridSearchCV(logreg, param_grid = grid, cv = 5, scoring='accuracy', verbose = 1, n_jobs = -1)\n",
    "best_model = lr.fit(X_train, y_train)\n",
    "\n",
    "print(best_model.best_estimator_)\n",
    "print(best_model.best_score_)\n",
    "\n",
    "y_pred_grid = best_model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred_grid))\n",
    "print(classification_report(y_test, y_pred_grid))\n",
    "print(accuracy_score(y_test, y_pred_grid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
