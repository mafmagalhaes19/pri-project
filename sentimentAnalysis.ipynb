{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, gzip \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/final_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0','name', 'city', 'cuisine_style', 'ranking', 'price_range', 'number_of_reviews', 'restaurant_url'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop any rows w/ missing values\n",
    "df = df.dropna()\n",
    "# discover the actual counts\n",
    "df.rating.value_counts()\n",
    "# set sample size to labels w/ minimum count\n",
    "sample_size = 50000\n",
    "df_equal_overall = pd.DataFrame()\n",
    "for i in df.rating.unique():\n",
    "  X = df[df.rating == i].sample(sample_size, replace=True)\n",
    "  df_equal_overall = df_equal_overall.append(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental preprocessing tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "def ReviewProcessing(df):\n",
    "  # remove non alphanumeric \n",
    "  df['review_cleaned'] = df.reviews.str.replace('[^a-zA-Z0-9 ]', '')\n",
    "  # lowercase\n",
    "  df.review_cleaned = df.review_cleaned.str.lower()\n",
    "  # split into list\n",
    "  df.review_cleaned = df.review_cleaned.str.split(' ')\n",
    "  # remove stopwords\n",
    "  df.review_cleaned = df.review_cleaned.apply(lambda x: [item for item in x if item not in stopwords_list])\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "  tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "  tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "  return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def get_lemmatize(sent):\n",
    "  return \" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sent)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = ReviewProcessing(df)\n",
    "clean_data.review_cleaned = clean_data.review_cleaned.apply(' '.join)\n",
    "clean_data['review_cleaned_lemmatized'] = clean_data.review_cleaned.apply(get_lemmatize)\n",
    "clean_data.drop(['Unnamed: 0','name', 'city', 'cuisine_style', 'ranking', 'price_range', 'number_of_reviews', 'restaurant_url'], axis=1)\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = clean_data['review_cleaned_lemmatized']\n",
    "y = clean_data['rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = Pipeline([('vectorize', CountVectorizer(ngram_range=(1, 2))),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier()),\n",
    "               ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(max_iter=500)),\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "print(\"Naive Bayes:\\n\")\n",
    "print(accuracy_score(y_test, y_pred_nb))\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "# SGD Classifier\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred_sgd = sgd.predict(X_test)\n",
    "print(\"SGD Classifier:\\n\")\n",
    "print(accuracy_score(y_test, y_pred_sgd))\n",
    "print(confusion_matrix(y_test, y_pred_sgd))\n",
    "print(classification_report(y_test, y_pred_sgd))\n",
    "\n",
    "# Logistic Regression\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_log = logreg.predict(X_test)\n",
    "print(\"Logistic regression:\\n\")\n",
    "print(accuracy_score(y_test, y_pred_log))\n",
    "print(confusion_matrix(y_test, y_pred_log))\n",
    "print(classification_report(y_test, y_pred_log))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
